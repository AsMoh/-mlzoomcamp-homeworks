{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc0f9379",
   "metadata": {},
   "source": [
    "The goal of this homework is to inspect the output of different evaluation metrics by creating a classification model (target column card).\n",
    "\n",
    "### Preparation\n",
    "- Create the target variable by mapping yes to 1 and no to 0.\n",
    "Split the dataset into 3 parts: train/validation/test with 60%/20%/20% distribution.Use train_test_split funciton for that with random_state=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e718558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ac7b4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('AER_credit_card_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "29ae5d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.58333</td>\n",
       "      <td>4.5660</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>23.91667</td>\n",
       "      <td>3.1920</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>40.58333</td>\n",
       "      <td>4.6000</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>101.298300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.83333</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>26.996670</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>48.25000</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.111619</td>\n",
       "      <td>344.157500</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0     yes        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1     yes        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2     yes        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3     yes        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4     yes        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "...   ...      ...       ...     ...       ...          ...   ...     ...   \n",
       "1314  yes        0  33.58333  4.5660  0.002146     7.333333   yes      no   \n",
       "1315   no        5  23.91667  3.1920  0.000376     0.000000    no      no   \n",
       "1316  yes        0  40.58333  4.6000  0.026513   101.298300   yes      no   \n",
       "1317  yes        0  32.83333  3.7000  0.008999    26.996670    no     yes   \n",
       "1318  yes        0  48.25000  3.7000  0.111619   344.157500   yes      no   \n",
       "\n",
       "      dependents  months  majorcards  active  \n",
       "0              3      54           1      12  \n",
       "1              3      34           1      13  \n",
       "2              4      58           1       5  \n",
       "3              0      25           1       7  \n",
       "4              2      64           1       5  \n",
       "...          ...     ...         ...     ...  \n",
       "1314           0      94           1      19  \n",
       "1315           3      12           1       5  \n",
       "1316           2       1           1       2  \n",
       "1317           0      60           1       7  \n",
       "1318           2       2           1       0  \n",
       "\n",
       "[1319 rows x 12 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d0604c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target']= (df['card'] == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "c7a94a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['card'], inplace= True , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "70cb4530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>0</td>\n",
       "      <td>33.58333</td>\n",
       "      <td>4.5660</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>5</td>\n",
       "      <td>23.91667</td>\n",
       "      <td>3.1920</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>0</td>\n",
       "      <td>40.58333</td>\n",
       "      <td>4.6000</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>101.298300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>0</td>\n",
       "      <td>32.83333</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>26.996670</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>0</td>\n",
       "      <td>48.25000</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>0.111619</td>\n",
       "      <td>344.157500</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reports       age  income     share  expenditure owner selfemp  \\\n",
       "0           0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1           0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2           0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3           0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4           0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "...       ...       ...     ...       ...          ...   ...     ...   \n",
       "1314        0  33.58333  4.5660  0.002146     7.333333   yes      no   \n",
       "1315        5  23.91667  3.1920  0.000376     0.000000    no      no   \n",
       "1316        0  40.58333  4.6000  0.026513   101.298300   yes      no   \n",
       "1317        0  32.83333  3.7000  0.008999    26.996670    no     yes   \n",
       "1318        0  48.25000  3.7000  0.111619   344.157500   yes      no   \n",
       "\n",
       "      dependents  months  majorcards  active  target  \n",
       "0              3      54           1      12       1  \n",
       "1              3      34           1      13       1  \n",
       "2              4      58           1       5       1  \n",
       "3              0      25           1       7       1  \n",
       "4              2      64           1       5       1  \n",
       "...          ...     ...         ...     ...     ...  \n",
       "1314           0      94           1      19       1  \n",
       "1315           3      12           1       5       0  \n",
       "1316           2       1           1       2       1  \n",
       "1317           0      60           1       7       1  \n",
       "1318           2       2           1       0       1  \n",
       "\n",
       "[1319 rows x 12 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "dd550a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_val=train_test_split(df, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "6620a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test=train_test_split(df_full_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8fbc88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=df_train.target.values\n",
    "y_val=df_val.target.values\n",
    "y_test=df_test.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "593db747",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['target']\n",
    "del df_val['target']\n",
    "del df_test['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "14464be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e544b91",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that <br>\n",
    "\n",
    "For each numerical variable, use it as score and compute AUC with the card variable. <br>\n",
    "Use the training dataset for that.  <br>\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front  <br>\n",
    "\n",
    "(e.g. -df_train['expenditure']) <br>\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8f7558d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 791 entries, 0 to 790\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   reports      791 non-null    int64  \n",
      " 1   age          791 non-null    float64\n",
      " 2   income       791 non-null    float64\n",
      " 3   share        791 non-null    float64\n",
      " 4   expenditure  791 non-null    float64\n",
      " 5   owner        791 non-null    object \n",
      " 6   selfemp      791 non-null    object \n",
      " 7   dependents   791 non-null    int64  \n",
      " 8   months       791 non-null    int64  \n",
      " 9   majorcards   791 non-null    int64  \n",
      " 10  active       791 non-null    int64  \n",
      "dtypes: float64(4), int64(5), object(2)\n",
      "memory usage: 68.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "2c77abee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reports        False\n",
       "age             True\n",
       "income          True\n",
       "share           True\n",
       "expenditure     True\n",
       "owner          False\n",
       "selfemp        False\n",
       "dependents     False\n",
       "months         False\n",
       "majorcards     False\n",
       "active         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes == np.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "4cd61b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reports',\n",
       " 'age',\n",
       " 'income',\n",
       " 'share',\n",
       " 'expenditure',\n",
       " 'dependents',\n",
       " 'months',\n",
       " 'majorcards',\n",
       " 'active']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features= list(df_train.drop(['owner','selfemp'], axis=1).columns)\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b8d44151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "96c21533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reports\n",
      "0.7166629860689376\n",
      "\n",
      "age\n",
      "0.5240020979407055\n",
      "\n",
      "income\n",
      "0.5908049467233478\n",
      "\n",
      "share\n",
      "0.989183643423692\n",
      "\n",
      "expenditure\n",
      "0.991042345276873\n",
      "\n",
      "dependents\n",
      "0.5327757227773791\n",
      "\n",
      "months\n",
      "0.5294217780967629\n",
      "\n",
      "majorcards\n",
      "0.5343859842838476\n",
      "\n",
      "active\n",
      "0.6043173411362006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc=[]\n",
    "for i in numerical_features:\n",
    "    print(i)\n",
    "    fps, tps, thresholds=roc_curve(y_train,df_train[i].values)\n",
    "    auc1=auc(fps,tps)\n",
    "    if auc1 < 0.5:\n",
    "        fps, tps, thresholds=roc_curve(y_train,-df_train[i].values)\n",
    "        auc1=auc(fps,tps)\n",
    "    print(auc1)\n",
    "    print()\n",
    "    sc.append(auc1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "2ca323fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "34f3af87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expenditure\n"
     ]
    }
   ],
   "source": [
    "print(numerical_features[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "e2b55e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "e42028b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  reports, 0.717\n",
      "      age, 0.524\n",
      "   income, 0.591\n",
      "    share, 0.989\n",
      "expenditure, 0.991\n",
      "dependents, 0.533\n",
      "   months, 0.529\n",
      "majorcards, 0.534\n",
      "   active, 0.604\n"
     ]
    }
   ],
   "source": [
    "for c in numerical_features:\n",
    "    auc = roc_auc_score(y_train, df_train[c])\n",
    "    if auc < 0.5:\n",
    "        auc = roc_auc_score(y_train, -df_train[c])\n",
    "    print('%9s, %.3f' % (c, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4815ef",
   "metadata": {},
   "source": [
    "Since expenditure is not in the list, share is the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636dfc3f",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "From now on, use these columns only: <br>\n",
    "\n",
    "[\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"] <br>\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:  <br>\n",
    "\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ea18b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e85f7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ccea82cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_train (df1, y):\n",
    "    dictVec=DictVectorizer(sparse=False)\n",
    "    X_dict=df1.to_dict(orient='records')\n",
    "    X_train=dictVec.fit_transform(X_dict)\n",
    "    \n",
    "    logR=LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    logR.fit(X_train,y_train)\n",
    "    \n",
    "    return dictVec, logR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "8fae9b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.36356852e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 9.99999936e-01, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       5.78398811e-02, 6.60333401e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.17511543e-04, 1.20591533e-01, 1.00000000e+00,\n",
       "       5.78889947e-02, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       9.96988601e-01, 1.00000000e+00, 9.96331601e-04, 1.00000000e+00,\n",
       "       1.86266071e-01, 2.33773019e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       5.67994921e-03, 2.11915994e-02, 1.04968772e-01, 1.00000000e+00,\n",
       "       1.00000000e+00, 8.25334189e-03, 1.00000000e+00, 1.84558052e-02,\n",
       "       1.00000000e+00, 9.99999999e-01, 4.76319948e-02, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 3.46206867e-02,\n",
       "       1.00000000e+00, 4.79572586e-03, 1.39483942e-01, 1.00000000e+00,\n",
       "       5.18468345e-03, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 8.18545624e-03, 1.00000000e+00, 8.32084219e-03,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       2.04642696e-02, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       8.79289778e-02, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       4.59682763e-02, 2.89180838e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.32067139e-01,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.86095142e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 9.99992326e-01, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 9.99844514e-01, 2.72695247e-03, 1.00000000e+00,\n",
       "       1.00000000e+00, 9.99995480e-01, 1.00000000e+00, 1.22572222e-01,\n",
       "       1.00000000e+00, 1.00000000e+00, 2.11710297e-01, 4.44408432e-02,\n",
       "       1.00000000e+00, 1.00000000e+00, 3.63088570e-02, 1.00000000e+00,\n",
       "       9.99999993e-01, 1.55451694e-01, 9.99999664e-01, 1.00000000e+00,\n",
       "       9.99885081e-01, 2.44022328e-04, 3.13108757e-02, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.42526189e-01, 1.25312712e-01, 1.00000000e+00,\n",
       "       1.86747589e-01, 1.00000000e+00, 7.66180715e-03, 1.78102267e-01,\n",
       "       1.00000000e+00, 1.02010299e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.16813349e-01, 2.20564761e-04, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 2.23331770e-02,\n",
       "       1.00000000e+00, 1.71522195e-03, 9.98848614e-01, 5.64368133e-07,\n",
       "       9.98131966e-01, 1.00000000e+00, 1.83545603e-02, 1.00000000e+00,\n",
       "       1.42711043e-02, 1.00000000e+00, 4.14240264e-05, 1.92408494e-02,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.20599886e-03,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.38993928e-01, 7.49591137e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.38515354e-01,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 2.33633261e-01,\n",
       "       1.00000000e+00, 6.24516767e-06, 1.00000000e+00, 4.43787371e-03,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 9.23651793e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "       2.02784429e-02, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 4.13574587e-01, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.52624550e-01, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       5.14752481e-02, 1.00000000e+00, 1.00000000e+00, 2.85915842e-01,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.58438767e-06, 1.00000000e+00,\n",
       "       3.79995894e-03, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.72968375e-01, 1.00000000e+00, 1.00000000e+00, 3.10251228e-02,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 8.25780603e-03,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 2.54609794e-02])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictv0, model=encode_and_train(df_train, y_train)\n",
    "X_dict_val=df_val.to_dict(orient='records')\n",
    "X_val=dictv0.transform(X_dict_val)\n",
    "\n",
    "y_pridected=model.predict_proba(X_val)[:, 1]\n",
    "y_pridected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "52737ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pridected1=(y_pridected >=0.5).astype(int)\n",
    "y_pridected1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b15ca93",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "446c870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ab9c0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr, ths=roc_curve(y_val,y_pridected1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8b260d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(auc(fpr,tpr), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da3eb3",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Now let's compute precision and recall for our model. <br>\n",
    "\n",
    "Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01 <br>\n",
    "For each threshold, compute precision and recall <br>\n",
    "Plot them <br>\n",
    "At which threshold precision and recall curves intersect?  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b48060dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score(tp,fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def precision_score(tp,fn):\n",
    "    return tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "1bb3aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "\n",
    "for t in thresholds:\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "\n",
    "    predict_positive = (y_pridected >= t)\n",
    "    predict_negative = (y_pridected < t)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    recall_scores.append(recall_score(tp,fn))\n",
    "    precision_scores.append(precision_score(tp,fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "5f72376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "74bc1deb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f3b9e9abb0>"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds,recall_scores , label='recall')\n",
    "plt.plot(thresholds, precision_scores, label='precision')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b118d4b",
   "metadata": {},
   "source": [
    "At which threshold precision and recall curves intersect? at 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661be72",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "<br>\n",
    "This is the formula for computing F1: <br>\n",
    "\n",
    "F1 = 2 * P * R / (P + R)  <br>\n",
    "\n",
    "Where P is precision and R is recall.  <br>\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "a03bc7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(P,R):\n",
    "    F1 = 2 * P * R / (P + R)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b4ae40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "F1_scores= []\n",
    "for i in range(0 , len(recall_scores)):\n",
    "    F1_scores.append(F1_score(precision_scores[i], recall_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ed006f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(F1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1c191cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 is maximum at threshold 0.42\n"
     ]
    }
   ],
   "source": [
    "print(f\" F1 is maximum at threshold {thresholds[np.argmax(F1_scores)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea4c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d01aabb2",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds: <br>\n",
    "\n",
    "- KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "- Iterate over different folds of df_full_train\n",
    "- Split the data into train and validation\n",
    "- Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "- Use AUC to evaluate the model on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "8b8b1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c3e75987",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e4ecfff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AUC: 1.0\n",
      " AUC: 0.99375\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "scores_kfolds=[]\n",
    "for train_idx, val_idx in kf.split(df_full_train):\n",
    "    df_train=df_full_train.iloc[train_idx]\n",
    "    df_val= df_full_train.iloc[val_idx]\n",
    "    \n",
    "    y_train=df_train['target']\n",
    "    y_val=df_val['target']\n",
    "    \n",
    "    dictv0, model=encode_and_train(df_train, y_train)\n",
    "    X_dict_val=df_val.to_dict(orient='records')\n",
    "    X_val=dictv0.transform(X_dict_val)\n",
    "    y_predicted=model.predict_proba(X_val)[:,1]\n",
    "    y_predicted=(y_predicted >=0.5).astype(int)\n",
    "    fpr,tpr, ths=roc_curve(y_val,y_predicted)\n",
    "    auc_value=auc(fpr,tpr)\n",
    "    print(f\" AUC: {auc_value}\")\n",
    "    scores_kfolds.append(auc_value)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2230d65",
   "metadata": {},
   "source": [
    "- How large is standard devidation of the AUC scores across different folds?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "fffbe993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(scores_kfolds) , 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba8d6a1",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C  <br>\n",
    "\n",
    "- Iterate over the following C values: [0.01, 0.1, 1, 10]\n",
    "- Initialize KFold with the same parameters as previously\n",
    "- Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "- Compute the mean score as well as the std (round the mean and std to 3 decimal digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "b7f7df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_train (df1, y , c):\n",
    "    dictVec=DictVectorizer(sparse=False)\n",
    "    X_dict=df1.to_dict(orient='records')\n",
    "    X_train=dictVec.fit_transform(X_dict)\n",
    "    \n",
    "    logR=LogisticRegression(solver='liblinear', C=c, max_iter=1000)\n",
    "    logR.fit(X_train,y_train)\n",
    "    \n",
    "    return dictVec, logR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "405cc602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AUC: 0.9791666666666667\n",
      " AUC: 0.98125\n",
      " AUC: 0.9848484848484849\n",
      " AUC: 0.9908536585365854\n",
      " AUC: 0.9970238095238095\n",
      " AUC: 0.9791666666666667\n",
      " AUC: 0.984375\n",
      " AUC: 0.9848484848484849\n",
      " AUC: 0.9939024390243902\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n",
      " AUC: 0.99375\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n",
      " AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "params_scores_std=[]\n",
    "params_scores_mean=[]\n",
    "params_scores=[]\n",
    "\n",
    "for i in  [0.01, 0.1, 1, 10]:\n",
    "    scores_kfolds=[]\n",
    "\n",
    "    for train_idx, val_idx in kf.split(df_full_train):\n",
    "        df_train=df_full_train.iloc[train_idx]\n",
    "        df_val= df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train=df_train['target']\n",
    "        y_val=df_val['target']\n",
    "\n",
    "        dictv0, model=encode_and_train(df_train, y_train,i)\n",
    "        X_dict_val=df_val.to_dict(orient='records')\n",
    "        X_val=dictv0.transform(X_dict_val)\n",
    "        y_predicted=model.predict_proba(X_val)[:,1]\n",
    "        y_predicted=(y_predicted >=0.5).astype(int)\n",
    "        fpr,tpr, ths=roc_curve(y_val,y_predicted)\n",
    "        auc_value=auc(fpr,tpr)\n",
    "        print(f\" AUC: {auc_value}\")\n",
    "        scores_kfolds.append(auc_value)\n",
    "    \n",
    "    params_scores.append((round(np.std(scores_kfolds) , 3) , round(np.mean(scores_kfolds) , 3)) )\n",
    "    params_scores_std.append(round(np.std(scores_kfolds) , 3))\n",
    "    params_scores_mean.append(round(np.mean(scores_kfolds) , 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "f18c6f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.007, 0.987), (0.007, 0.988), (0.002, 0.999), (0.0, 1.0)]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1efb4e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007, 0.007, 0.002, 0.0]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "b4a1949d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.987, 0.988, 0.999, 1.0]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_scores_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b7311",
   "metadata": {},
   "source": [
    "Which C leads to the best mean score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "6e3588d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.01, 0.1, 1, 10][np.argmax(params_scores_mean)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d9ea1a",
   "metadata": {},
   "source": [
    "C= 10 is the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f82f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
